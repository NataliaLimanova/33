33.6 Практическая работа
Цель задания
Разработать пайплайн обучения ML-модели.



Что нужно сделать
Скачать архив с проектом airflow_hw, внутри него:
шаблон DAG’а (dags/hw_dag.py),
готовый код ML-модели (modules/pipeline.py),
шаблон скрипта для прогноза моделью (modules/predict.py),
данные для обучения и тестирования (data/train, data/test),
пустые папки под сохранение ML-модели и предсказаний.
Положить папку airflow_hw в домашнюю директорию (~/) и открыть её в Pycharm.
Запустить пайплайн с моделью локально и в Airflow, это обучит и сохранит объект с пайплайном лучшей модели в pickle формате:
локально: python3 modules/pipeline.py (из терминала Pycharm).
в Airflow: скопировать файл hw_dag.py в папку $AIRFLOW_HOME/dags.

После этого в интерфейсе отобразится новый DAG:
Написать код в файле modules/predict.py, который при вызове функции predict():
загружает обученную модель,
делает предсказания для всех объектов в папке data/test,
объединяет предсказания в один Dataframe и сохраняет их в csv-формате в папку data/predictions.

Не забываем разбивать код на смысловые части в виде отдельных функций.
Проверить корректность кода, запустив его локально: python3modules/predict.py (из терминала Pycharm)
Встроить прогноз моделью в пайплайн, в котором будет 2 шага:
pipeline — здесь выполняется функция pipeline,
predict — здесь делается предикт для всех объектов и сохраняется в папку data/predictions.
Запустить пайплайн в интерфейсе Airflow и получить предикты модели.


Советы и рекомендации
Целевая структура проекта выглядит так:
Работа с файлами проекта будет зависеть от способа развертывания Airflow:
локально: Airflow живёт в домашней директории (~/airflow) вашей операционной системы, папка с проектом располагается рядом (~/airflow_hw). При запуске DAG результаты будут записываться сразу в папку проекта, дополнительных действий не потребуется; содержимое файла предсказания можно посмотреть так:
Инструкцию по развертыванию Airflow вы можете скачать в разделе «Материалы». 


Критерии оценивания
Структура проекта и логика файлов modules/predict и dags/hw_dag соответствуют заданию. 
DAG с пайплайном модели из двух шагов (pipeline, predict) работает и сохраняет предсказания в файл (приложен скриншот с содержимым файла с предиктами модели).
Папка Airflow содержит только файлы самого Airflow. В папку dags скопированы файлы DAG’ов из папки с проектом. (Файлы проекта и папка Airflow существуют раздельно.)

Как отправить работу на проверку
Код проекта (папка airflow_hw) выложить на Github в личный репозиторий. 
Для возможности проверки сделать его публичным (public). 
Ссылку на репозиторий прикрепить через форму ниже, туда же скриншот с содержимым файла с предиктами модели, как результат работы итогового DAG.


P. S. Интересные факты, которые вы могли заметить при работе с Airflow:

В файле modules/pipeline.py вы наверняка заметите, что отладочная информация о качестве ML-моделей теперь выводится не через print(), а с помощью модуля logging. В реальных задачах справочную информацию принято логировать таким образом. Благодаря этому, в логах задач в Airflow мы сможем читать всю нужную нам информацию (время, файл и так далее):
Также вы можете заметить в коде typing — это конструкции вида func(value: int) -> str:.
Это означает, что функция func принимает аргумент типа int, а возвращает значение типа string. Это помогает понимать тип данных при написании кода. При этом надо помнить, что Python обладает динамической типизацией, и такая аннотация — это лишь подсказка для удобства разработчика.
В папке проекта есть файл .gitignore. Он поможет вам не отслеживать файлы с данными при выкладывании кода в ваш репозиторий GitHub:
